---
title: Quickstart
description: Get Trace OCR running locally and make your first request
---

## Prerequisites

- [Docker](https://docs.docker.com/get-docker/) and Docker Compose
- An HTTP client (`curl`, Python `requests`, or similar)

## Start the server

<Steps>
  <Step title="Clone the repository">
    ```bash
    git clone https://github.com/trace-co/trace-doctr.git
    cd trace-doctr/api
    ```
  </Step>
  <Step title="Generate the lock file">
    ```bash
    make lock
    ```
    This requires [Poetry](https://python-poetry.org/) to be installed.
  </Step>
  <Step title="Start the API">
    ```bash
    make run
    ```
    The API starts at `http://localhost:8080`. The first startup takes a few minutes as Docker builds the image and downloads model weights from Hugging Face.
  </Step>
</Steps>

Once running, open `http://localhost:8080/docs` for the interactive Swagger UI.

## Make your first OCR request

<CodeGroup>
```bash curl
curl -X POST http://localhost:8080/ocr/ \
  -F "files=@document.jpg"
```

```python Python
import requests

with open("document.jpg", "rb") as f:
    response = requests.post(
        "http://localhost:8080/ocr/",
        files={"files": ("document.jpg", f, "image/jpeg")},
    )

print(response.json())
```

```javascript JavaScript
const form = new FormData();
form.append("files", new Blob([fileBuffer]), "document.jpg");

const response = await fetch("http://localhost:8080/ocr/", {
  method: "POST",
  body: form,
});

const result = await response.json();
console.log(result);
```
</CodeGroup>

## Response structure

The `/ocr` endpoint returns an array of results, one per uploaded file:

```json
[
  {
    "name": "document.jpg",
    "orientation": { "value": 0.0, "confidence": 0.99 },
    "language": { "value": "en", "confidence": 0.99 },
    "dimensions": [1920, 1080],
    "pages": [
      {
        "blocks": [
          {
            "geometry": [0.12, 0.05, 0.88, 0.15],
            "detection_score": 0.97,
            "lines": [
              {
                "geometry": [0.12, 0.05, 0.88, 0.10],
                "detection_score": 0.97,
                "words": [
                  {
                    "value": "Hello",
                    "geometry": [0.12, 0.05, 0.30, 0.10],
                    "detection_score": 0.97,
                    "confidence": 0.99,
                    "text_orientation": { "value": 0, "confidence": null }
                  }
                ]
              }
            ]
          }
        ]
      }
    ]
  }
]
```

Each word includes:
- **value** — the recognized text
- **geometry** — normalized bounding box coordinates `[x_min, y_min, x_max, y_max]` where values range from 0 to 1 relative to the page dimensions
- **confidence** — recognition confidence (0 to 1)
- **detection_score** — how confident the detector is that this region contains text

## Customize model parameters

Pass query parameters to change models or tune thresholds:

```bash
curl -X POST "http://localhost:8080/ocr/?detection_model=fast_base&recognition_model=parseq&binary_threshold=0.3" \
  -F "files=@document.jpg"
```

See [Available models](/concepts/models) for the full list of architectures.

## Supported file formats

<Snippet file="supported-formats.mdx" />

## Stop the server

```bash
cd trace-doctr/api
make stop
```
